{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"resize images in the train folder\")\n",
    "folder =\"train/clean/\"\n",
    "#copy_folder=\"images_r/train/nonwaste/\"\n",
    "w = int(224)\n",
    "h = int(224)\n",
    "for i in os.listdir(folder):\n",
    "    file = f\"{folder}/{i}\"\n",
    "    im = Image.open(file)\n",
    "    im = im.resize((w, h), Image.ANTIALIAS)\n",
    "    im.save(file) \n",
    "   \n",
    "print(\"resize images in the train folder\")\n",
    "folder =\"train/waste/\"\n",
    "#copy_folder=\"images_r/train/nonwaste/\"\n",
    "w = int(224)\n",
    "h = int(224)\n",
    "for i in os.listdir(folder):\n",
    "    file = f\"{folder}/{i}\"\n",
    "    im = Image.open(file)\n",
    "    im = im.resize((w, h), Image.ANTIALIAS)\n",
    "    im.save(file)\n",
    "    \n",
    "print(\"resize images in the val folder\")\n",
    "folder =\"validation/waste/\"\n",
    "#copy_folder=\"images_r/train/nonwaste/\"\n",
    "w = int(224)\n",
    "h = int(224)\n",
    "for i in os.listdir(folder):\n",
    "    file = f\"{folder}/{i}\"\n",
    "    im = Image.open(file)\n",
    "    im = im.resize((w, h), Image.ANTIALIAS)\n",
    "    im.save(file)     \n",
    "\n",
    "print(\"resize images in the val folder\")\n",
    "folder =\"validation/clean/\"\n",
    "#copy_folder=\"images_r/train/nonwaste/\"\n",
    "w = int(224)\n",
    "h = int(224)\n",
    "for i in os.listdir(folder):\n",
    "    file = f\"{folder}/{i}\"\n",
    "    im = Image.open(file)\n",
    "    im = im.resize((w, h), Image.ANTIALIAS)\n",
    "    im.save(file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_datagen.flow_from_directory('train/',target_size=(224,224),batch_size=3,class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ds = validation.flow_from_directory('validation/',target_size=(224,224),batch_size=3,class_mode='binary')\n",
    "#test_ds = validation.flow_from_directory('validation/',target_size=(224,224),batch_size=3,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(224,224,3)),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "                                    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "                                    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512,activation='relu'),\n",
    "                                    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "                                    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                    mode =\"min\", patience = 5, \n",
    "                                       restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(train_ds,\n",
    "                   epochs=30,batch_size=15,\n",
    "                     validation_data=validation_ds, callbacks =[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_fit.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model_fit.history['accuracy'])\n",
    "plt.plot(model_fit.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_fit.history['loss'])\n",
    "plt.plot(model_fit.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator()\n",
    "\n",
    "test_ds = test_generator.flow_from_directory(directory=r\"./test/\",\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=1,\n",
    "                                                    class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_ds.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "Y_pred = model.predict_generator(test_ds,steps=np.ceil(test_ds.samples/test_ds.batch_size),verbose=1,workers=0)\n",
    "#y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = np.where(Y_pred>0.5,1,0)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_ds.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = test_ds.classes\n",
    "class_labels = list(test_ds.class_indices.keys()) \n",
    "\n",
    "report = classification_report(target_names, y_pred, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'test/waste'\n",
    "for i in os.listdir(dir_path):\n",
    "  img = image.load_img(dir_path+'//' + i,target_size=(224,224))\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "\n",
    "  X=image.img_to_array(img)\n",
    "  X=np.expand_dims(X,axis=0)\n",
    "  images = np.vstack([X])\n",
    "  val = model.predict(images)\n",
    "  if val == 0:\n",
    "    print(\"The given image is clean\")\n",
    "  else:\n",
    "    print(\"The given image is waste\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json_50_84 = model.to_json()\n",
    "with open(\"model50_84.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json_50_84)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"cnn50_84.h5\")\n",
    "print(\"Saved model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "json_file = open('model32_98.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"cnn32_87.h5\")\n",
    "print(\"Loaded model\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
